{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umerfarooq122/Text-Summarization-by-Fine-tuning-a-pre-trained-transformer-PEGASUS-from-hugging-face-library/blob/main/PEGASUS_on_Samsum%2C_PubMed_and_Arxiv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOoAGzuEcKXI"
      },
      "source": [
        "### **Text Summarization Using Pre-training with Extracted Gap-sentences for Abstractive Summarization (PEGASUS) from Huggingface**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpVKqRocxza"
      },
      "source": [
        "#### **Environment Setup:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13XOm5WdnteE"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_metric py7zr -q\n",
        "!pip3 install -q -U bitsandbytes\n",
        "!pip3 install -q -U peft\n",
        "!pip3 install -q -U trl\n",
        "!pip3 install -q -U accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mKjCs7VWieW",
        "outputId": "112135f8-c082-417b-e0e8-139142b7dcbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets --upgrade\n",
        "!pip install evaluate --upgrade\n",
        "!pip install rouge_score --upgrade\n",
        "!pip install transformers --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmesKwR6HbDW",
        "outputId": "7c277bab-bebc-42b4-f4aa-b4102ba8eff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig, BigBirdPegasusForConditionalGeneration, PegasusForConditionalGeneration, PegasusTokenizer\n",
        "from peft import PeftModel, LoraConfig\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Acc0g0g8IPCK",
        "outputId": "652d4231-e43a-4bf3-ce71-4c62d1385393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4T3VmgDdAVt"
      },
      "source": [
        "### **PEGASUS large:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAoHkcexO3Kj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b0cf1f-3249-46ea-d498-52551de14ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_large = \"google/pegasus-large\"\n",
        "tokenizer_large = AutoTokenizer.from_pretrained(\"google/pegasus-large\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Set the environment variable to enable more verbose error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "GD3Eu4MQgeyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KW3Hzl6Pbig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8cdf24-d5cc-49b1-c9ca-86081a182a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#model_pega = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
        "model_pega = AutoModelForSeq2SeqLM.from_pretrained(model_large)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqE-Z-8TdHi1"
      },
      "source": [
        "#### **PubMED Dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fACpPUNFQI0U",
        "outputId": "f9c539e1-8198-4255-b327-519cf01fcdfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 14732\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 819\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 818\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset_science = load_dataset(\"ccdv/pubmed-summarization\", trust_remote_code=True)\n",
        "dataset_science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGPQ0VLwdO-F"
      },
      "source": [
        "##### **Splitting the Dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mQvVM1-QWR7",
        "outputId": "6e7c467b-2125-490a-8c5a-796e84a25118"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14732, 819, 818]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "split_lengths = [len(dataset_science[split]) for split in dataset_science]\n",
        "split_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM6GuZheQwCE",
        "outputId": "445ef94d-ead1-4e5e-fdc8-9c82751146a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['id', 'dialogue', 'summary']\n"
          ]
        }
      ],
      "source": [
        "print(f\"Features: {dataset_science['train'].column_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta_J5F7kQzKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9408a5fe-1862-413b-bfdc-c4f47101d4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Article:\n",
            "Amanda: I baked  cookies. Do you want some?\r\n",
            "Jerry: Sure!\r\n",
            "Amanda: I'll bring you tomorrow :-)\n",
            "\n",
            "Abstract:\n",
            "Amanda baked cookies and will bring Jerry some tomorrow.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nArticle:\")\n",
        "print(dataset_science[\"train\"][0]['article'])\n",
        "print(\"\\nAbstract:\")\n",
        "print(dataset_science[\"train\"][0]['abstract'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43IjDWVzdmO3"
      },
      "source": [
        "##### **Test Running Raw Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZamWJiDRItO"
      },
      "outputs": [],
      "source": [
        "dialogue = dataset_science[\"train\"][1][\"article\"]\n",
        "summary = dataset_science[\"train\"][1][\"abstract\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2NSNHznS_FT"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"summarization\", model=model_pega, tokenizer=tokenizer_large, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV3YrJfDwdxE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4VSnMMxTQ7B"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_length = 4000 # Set a suitable maximum length for your input\n",
        "\n",
        " #Truncate dialogue if it exceeds max_length\n",
        "if len(dialogue) > max_length:\n",
        "    dialogue = dialogue[:max_length]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bV4SK7C8mL2w",
        "outputId": "2cfd9d5b-337d-450f-894e-66071d521b31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olivia: Who are you voting for in this election? \\r\\nOliver: Liberals as always.\\r\\nOlivia: Me too!!\\r\\nOliver: Great'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "dialogue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M7aCim-RYnZc",
        "outputId": "dc4250ad-f8b5-45b9-f171-d4455d5e4bc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olivia and Olivier are voting for liberals in this election. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l31DX7afhL0k"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer_large, model = model_pega)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "S2vb1okGmIsx",
        "outputId": "9aa6299a-4f3c-48c5-9a2e-37d2a6912a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 128, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Olivia: Who's you voting for in this election? Oliver: Liberals as always .<n>Olivia: Me too!!<n>Oliver: Great .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "pipe_out = pipe(dialogue)\n",
        "pipe_outp = pipe_out[0][\"summary_text\"]\n",
        "pipe_outp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDYGq1bRymvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ee652e-51fb-4ffc-9696-b32a71af2b9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ''}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "pipe_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO_OPHI9TwpE"
      },
      "outputs": [],
      "source": [
        "#print(pipe_outp.replace(\" . <n>\", \".\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GSqmM9OgNg0"
      },
      "outputs": [],
      "source": [
        "#summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4TQW8Fhdw5t"
      },
      "source": [
        "##### **Evaluating The Performance of Raw Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V17Hqfy_Ud26"
      },
      "outputs": [],
      "source": [
        "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
        "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
        "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]\n",
        "\n",
        "def calculate_metric_on_TEST_ds(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"abstract\"):\n",
        "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
        "    for article_batch, target_batch in tqdm(\n",
        "        zip(article_batches, target_batches), total=len(article_batches)):\n",
        "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                clean_up_tokenization_spaces=True)\n",
        "               for s in summaries]\n",
        "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "    return metric.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvb0NdAFUI-S",
        "outputId": "9516e8fb-97d3-4b30-deec-a99c108744c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:09<00:00,  1.87s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rouge_metric = load(\"rouge\")\n",
        "\n",
        "score = calculate_metric_on_TEST_ds(dataset_science[\"train\"][0:10], rouge_metric, model_pega, tokenizer_large, batch_size=2, column_text=\"article\", column_summary='abstract')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AICK8NqEaRI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0c289e-5aa1-4fa6-f792-3a5fbf2e2e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           rouge1  rouge2    rougeL  rougeLsum\n",
            "pegasus  0.007424     0.0  0.007242   0.007415\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "rouge_dict = {rn: score[rn] for rn in rouge_names}\n",
        "print(pd.DataFrame(rouge_dict, index=[\"pegasus\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrAOQFzwd7cb"
      },
      "source": [
        "##### **Fine-Tuning PEGASUS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH3Y1BVieNau"
      },
      "source": [
        "###### **Tokenizing The Text:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwXW-OWMynxq",
        "outputId": "32415a34-de28-4d30-974a-0918143cfeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4845\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer_large(dialogue, return_tensors=\"pt\").input_ids\n",
        "num_tokens = tokens.shape[1]\n",
        "print(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "4a23a3538f7642fab0e534b7eba407cb",
            "d6b141aba9e84397b3f05c8b14dabb35",
            "a255cde357494fe28eb057db6005e5bd",
            "c9cdf46a5805402a89f41cd0318f7a05",
            "c384e88fb20346fd95937c5687b64da9",
            "83ed9efeb0e1474ca81895dece7f7769",
            "427a36865b35465c94d5d3201c2b591a",
            "2e46986247a24377b23b436744f95cab",
            "e7168c60788e495b8746e41b3fddb82b",
            "505970ca58f148f5ad5e1bc33df18dda",
            "10f7090ef4d44d378693b0258dcca3f0"
          ]
        },
        "id": "53t_7SuP4MWg",
        "outputId": "48654422-f256-4525-cba8-e8770514c456"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a23a3538f7642fab0e534b7eba407cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "\n",
        "  input_encodings = tokenizer_large(example_batch[\"dialogue\"], max_length=1024, truncation=True)\n",
        "  with tokenizer_large.as_target_tokenizer():\n",
        "      target_encodings = tokenizer_large(example_batch[\"summary\"], max_length=256, truncation=True)\n",
        "  return {\n",
        "        \"input_ids\": input_encodings[\"input_ids\"],\n",
        "        \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "        \"labels\": target_encodings[\"input_ids\"]\n",
        "    }\n",
        "dataset_science_pt = dataset_science.map(convert_examples_to_features, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eojyuIvJ58kL"
      },
      "outputs": [],
      "source": [
        "#dataset_science_pt[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT_SDMyO6FI4"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer_large, model = model_pega)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(r = 8, target_modules = [\"q_proj\",\"o_proj\",\"k_proj\", \"v_proj\",\n",
        "                                                  \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                         task_type = \"CAUSAL_LM\",)"
      ],
      "metadata": {
        "id": "JgNnu8qqxlhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbIweZnweFBq"
      },
      "source": [
        "###### **Setting The Training Arguments:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir=\"pegasus-science\",\n",
        "    num_train_epochs=5,  # Reduced for monitoring potential overfitting\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=2,  # Increased batch size, if possible\n",
        "    per_device_eval_batch_size=2,\n",
        "    weight_decay=0.005,  # Adjusted for potential improvement\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,  # More frequent evaluations\n",
        "    save_steps=1000,  # More frequent saves\n",
        "    gradient_accumulation_steps=8,  # Reduced to speed up updates\n",
        "    fp16=True  # Enable mixed precision if hardware supports it\n",
        ")\n"
      ],
      "metadata": {
        "id": "-w4fg68MX5gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnXo4f8HeY9t"
      },
      "source": [
        "###### **Training The Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0ww1EjU7Aoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93561b36-94dd-4f6a-f552-b63bce93639c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = SFTTrainer(model=model_pega, args=trainer_args,\n",
        "                  processing_class=tokenizer_large, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_science_pt[\"train\"],\n",
        "                  eval_dataset=dataset_science_pt[\"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "Qh9pvzDa0-5M",
        "outputId": "81f51dc6-4913-40e0-95d9-2eb47b022b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mumer5764\u001b[0m (\u001b[33mumer5764-the-city-university-of-new-york\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241204_125459-j7oc99s1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/umer5764-the-city-university-of-new-york/huggingface/runs/j7oc99s1' target=\"_blank\">pegasus-science</a></strong> to <a href='https://wandb.ai/umer5764-the-city-university-of-new-york/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/umer5764-the-city-university-of-new-york/huggingface' target=\"_blank\">https://wandb.ai/umer5764-the-city-university-of-new-york/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/umer5764-the-city-university-of-new-york/huggingface/runs/j7oc99s1' target=\"_blank\">https://wandb.ai/umer5764-the-city-university-of-new-york/huggingface/runs/j7oc99s1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [285/285 53:37, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.038600</td>\n",
              "      <td>2.496256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.869300</td>\n",
              "      <td>2.313674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.566900</td>\n",
              "      <td>2.116806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.332000</td>\n",
              "      <td>1.957790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.164200</td>\n",
              "      <td>1.834884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.981300</td>\n",
              "      <td>1.753219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.899400</td>\n",
              "      <td>1.692867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.835800</td>\n",
              "      <td>1.645342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.781300</td>\n",
              "      <td>1.608661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.741000</td>\n",
              "      <td>1.582273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.700600</td>\n",
              "      <td>1.561272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.683600</td>\n",
              "      <td>1.544026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.648800</td>\n",
              "      <td>1.531988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.648900</td>\n",
              "      <td>1.516594</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=285, training_loss=2.076021268074973, metrics={'train_runtime': 3229.5937, 'train_samples_per_second': 22.808, 'train_steps_per_second': 0.088, 'total_flos': 6.217592416980173e+16, 'train_loss': 2.076021268074973, 'epoch': 4.964169381107492})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kW36H6_egqb"
      },
      "source": [
        "###### **Evaluating The Performance:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4OvmCf15Fnx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "f8e68942-4a50-4e26-9297-80e7dd8d2f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 410/410 [08:37<00:00,  1.26s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           rouge1    rouge2    rougeL  rougeLsum\n",
              "pegasus  0.018438  0.000304  0.018302   0.018338"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-767a1534-0a8d-4dd0-9d26-3f7c14eeba72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.018438</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>0.018302</td>\n",
              "      <td>0.018338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-767a1534-0a8d-4dd0-9d26-3f7c14eeba72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-767a1534-0a8d-4dd0-9d26-3f7c14eeba72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-767a1534-0a8d-4dd0-9d26-3f7c14eeba72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.018437674688160214,\n        \"max\": 0.018437674688160214,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018437674688160214\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0003040312614425789,\n        \"max\": 0.0003040312614425789,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0003040312614425789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.018302299769078042,\n        \"max\": 0.018302299769078042,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018302299769078042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.01833830334818761,\n        \"max\": 0.01833830334818761,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.01833830334818761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "score = calculate_metric_on_TEST_ds(dataset_science[\"test\"], rouge_metric, model_pega, tokenizer_large, batch_size=2, column_text=\"article\", column_summary=\"abstract\")\n",
        "rouge_dict = {rn: score[rn] for rn in rouge_names}\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus-PubMed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyr3Ysz9en6Z"
      },
      "source": [
        "###### **Saving The Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNYkw_YjmzzX"
      },
      "outputs": [],
      "source": [
        "model_pega.save_pretrained(\"pegasus-science-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SOptqqAs6Y-"
      },
      "outputs": [],
      "source": [
        "tokenizer_large.save_pretrained(\"pegasus-science-tokenizer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI0jqvK48klk"
      },
      "source": [
        "#### **Arxiv Dataset:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Loading Dataset:**"
      ],
      "metadata": {
        "id": "2GrdIJCMDNMu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_-ya8zP8pUz"
      },
      "outputs": [],
      "source": [
        "data_arxiv = load_dataset(\"ccdv/arxiv-summarization\", trust_remote_code=True)\n",
        "data_arxiv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Tokenizing Data:**"
      ],
      "metadata": {
        "id": "tJ0tXlOxDlna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0LJunPBRJIo"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "\n",
        "  input_encodings = tokenizer_large(example_batch[\"article\"], max_length=1024, truncation=True)\n",
        "  with tokenizer_large.as_target_tokenizer():\n",
        "      target_encodings = tokenizer_large(example_batch[\"abstract\"], max_length=256, truncation=True)\n",
        "  return {\n",
        "        \"input_ids\": input_encodings[\"input_ids\"],\n",
        "        \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "        \"labels\": target_encodings[\"input_ids\"]\n",
        "    }\n",
        "dataset_arxiv_pt = data_arxiv.map(convert_examples_to_features, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Setting the training parameters:**"
      ],
      "metadata": {
        "id": "JKIIdRyBEXiv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIJ2qZUW_aAQ"
      },
      "outputs": [],
      "source": [
        "trainer_args = TrainingArguments(\n",
        "    output_dir=\"pegasus-science\",\n",
        "    num_train_epochs=5,  # Reduced for monitoring potential overfitting\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=2,  # Increased batch size, if possible\n",
        "    per_device_eval_batch_size=2,\n",
        "    weight_decay=0.005,  # Adjusted for potential improvement\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=20,  # More frequent evaluations\n",
        "    save_steps=1000,  # More frequent saves\n",
        "    gradient_accumulation_steps=8,  # Reduced to speed up updates\n",
        "    fp16=True  # Enable mixed precision if hardware supports it\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Training The Model:**"
      ],
      "metadata": {
        "id": "QBW1hwWyEqar"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcqK_QmXRAru"
      },
      "outputs": [],
      "source": [
        "Arxtrainer = SFTTrainer(model=model_pega, args=trainer_args,\n",
        "                  processing_class=tokenizer_large, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_arxiv_pt[\"train\"],\n",
        "                  eval_dataset=dataset_arxiv_pt[\"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u99ZmNc6DAwH"
      },
      "outputs": [],
      "source": [
        "Arxtrainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Evaluating The Performance:**"
      ],
      "metadata": {
        "id": "jh9VndQ1FJ7W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--kl9oMv3Vma"
      },
      "outputs": [],
      "source": [
        "score = calculate_metric_on_TEST_ds(data_arxiv[\"test\"], rouge_metric, model_pega, tokenizer_large, batch_size=2, column_text=\"article\", column_summary=\"abstract\")\n",
        "rouge_dict = {rn: score[rn] for rn in rouge_names}\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus-Arxiv\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Samsum Dataset:**"
      ],
      "metadata": {
        "id": "AIA67YW5GXn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Loading Dataset:**"
      ],
      "metadata": {
        "id": "hFs07BVPGgbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_samsum = load_dataset(\"Samsung/samsum\", trust_remote_code=True)\n",
        "data_samsum"
      ],
      "metadata": {
        "id": "Wd923CpNGfvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Tokenizing Data:**"
      ],
      "metadata": {
        "id": "Hn93sseIGm-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "\n",
        "  input_encodings = tokenizer_large(example_batch[\"dialogue\"], max_length=1024, truncation=True)\n",
        "  with tokenizer_large.as_target_tokenizer():\n",
        "      target_encodings = tokenizer_large(example_batch[\"summary\"], max_length=256, truncation=True)\n",
        "  return {\n",
        "        \"input_ids\": input_encodings[\"input_ids\"],\n",
        "        \"attention_mask\": input_encodings[\"attention_mask\"],\n",
        "        \"labels\": target_encodings[\"input_ids\"]\n",
        "    }\n",
        "dataset_samsum_pt = data_samsum.map(convert_examples_to_features, batched=True)"
      ],
      "metadata": {
        "id": "FHhuvaabGqBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Training The Model:**"
      ],
      "metadata": {
        "id": "2hSd099SHHDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samtrainer = SFTTrainer(model=model_pega, args=trainer_args,\n",
        "                  processing_class=tokenizer_large, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
      ],
      "metadata": {
        "id": "z3UwbnJsHHLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samtrainer.train()"
      ],
      "metadata": {
        "id": "qd5PVn2THQSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Evaluating The Performance:**"
      ],
      "metadata": {
        "id": "SkHtn7q0HScJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = calculate_metric_on_TEST_ds(data_samsum[\"test\"], rouge_metric, model_pega, tokenizer_large, batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n",
        "rouge_dict = {rn: score[rn] for rn in rouge_names}\n",
        "pd.DataFrame(rouge_dict, index=[\"pegasus-Samsum\"])"
      ],
      "metadata": {
        "id": "_0YZoendHVbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PEGASUS BigBird:**"
      ],
      "metadata": {
        "id": "UsQyoPLJHkcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading The Model:**"
      ],
      "metadata": {
        "id": "aOFViJSDH2ME"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yitAZQfAH-FY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1gI5NqBtSVwi-cQC1geuoYa24MkI_26Ts",
      "authorship_tag": "ABX9TyN0ZaBxfYE4jgePiXynBqeU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4a23a3538f7642fab0e534b7eba407cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6b141aba9e84397b3f05c8b14dabb35",
              "IPY_MODEL_a255cde357494fe28eb057db6005e5bd",
              "IPY_MODEL_c9cdf46a5805402a89f41cd0318f7a05"
            ],
            "layout": "IPY_MODEL_c384e88fb20346fd95937c5687b64da9"
          }
        },
        "d6b141aba9e84397b3f05c8b14dabb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ed9efeb0e1474ca81895dece7f7769",
            "placeholder": "​",
            "style": "IPY_MODEL_427a36865b35465c94d5d3201c2b591a",
            "value": "Map: 100%"
          }
        },
        "a255cde357494fe28eb057db6005e5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e46986247a24377b23b436744f95cab",
            "max": 819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7168c60788e495b8746e41b3fddb82b",
            "value": 819
          }
        },
        "c9cdf46a5805402a89f41cd0318f7a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_505970ca58f148f5ad5e1bc33df18dda",
            "placeholder": "​",
            "style": "IPY_MODEL_10f7090ef4d44d378693b0258dcca3f0",
            "value": " 819/819 [00:00&lt;00:00, 4903.64 examples/s]"
          }
        },
        "c384e88fb20346fd95937c5687b64da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ed9efeb0e1474ca81895dece7f7769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427a36865b35465c94d5d3201c2b591a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e46986247a24377b23b436744f95cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7168c60788e495b8746e41b3fddb82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "505970ca58f148f5ad5e1bc33df18dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f7090ef4d44d378693b0258dcca3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}